{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'ConfigProto'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c53350ac3003>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"
     ]
    }
   ],
   "source": [
    "# session 생성시 tf.Session()대신 tf.Session(config=config)로 대체 바랍니다!\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "'''\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "'''\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup layers\n",
    "# He Initialization\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "epsilon = 1e-3\n",
    "\n",
    "'''\n",
    "W1 = tf.Variable(tf.random_normal([784, 2048], stddev=0.01))\n",
    "#W1 = tf.get_variable(\"W1\", shape=[784, 1024], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "B1 = tf.Variable(tf.random_normal(shape=[2048], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1)+B1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "'''\n",
    "\n",
    "#W1_BN = tf.Variable(tf.random_normal([784, 2048], stddev=0.01))\n",
    "W1_BN = tf.get_variable(\"W1_BN\", shape=[784, 2048], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L1_BN = tf.matmul(X, W1_BN)\n",
    "batch_mean1, batch_var1 = tf.nn.moments(L1_BN,[0])\n",
    "scale1 = tf.Variable(tf.ones([2048]))\n",
    "beta1 = tf.Variable(tf.zeros([2048]))\n",
    "BN1 = tf.nn.batch_normalization(L1_BN, batch_mean1, batch_var1, beta1, scale1, epsilon)\n",
    "L1_BN = tf.nn.relu(BN1)\n",
    "L1_BN = tf.nn.dropout(L1_BN, keep_prob)\n",
    "\n",
    "'''\n",
    "W2 = tf.Variable(tf.random_normal([2048, 1024], stddev=0.01))\n",
    "#W1 = tf.get_variable(\"W1\", shape=[784, 1024], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "B2 = tf.Variable(tf.random_normal(shape=[1024], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1_BN, W2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "'''\n",
    "\n",
    "#W2_BN = tf.Variable(tf.random_normal([2048, 1024], stddev=0.01))\n",
    "W2_BN = tf.get_variable(\"W2_BN\", shape=[2048, 1024], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L2_BN = tf.matmul(L1_BN, W2_BN)\n",
    "batch_mean2, batch_var2 = tf.nn.moments(L2_BN,[0])\n",
    "scale2 = tf.Variable(tf.ones([1024]))\n",
    "beta2 = tf.Variable(tf.zeros([1024]))\n",
    "BN2 = tf.nn.batch_normalization(L2_BN, batch_mean2, batch_var2, beta2, scale2, epsilon)\n",
    "L2_BN = tf.nn.relu(BN2)\n",
    "L2_BN = tf.nn.dropout(L2_BN, keep_prob)\n",
    "\n",
    "'''\n",
    "W3 = tf.Variable(tf.random_normal([1024, 512], stddev=0.01))\n",
    "#W2 = tf.get_variable(\"W2\", shape=[1024, 512], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "B3 = tf.Variable(tf.random_normal(shape=[512], stddev=0.01))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3)+B3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n",
    "'''\n",
    "\n",
    "#W3_BN = tf.Variable(tf.random_normal([1024, 512], stddev=0.01))\n",
    "W3_BN = tf.get_variable(\"W3_BN\", shape=[1024, 512], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L3_BN = tf.matmul(L2_BN, W3_BN)\n",
    "batch_mean3, batch_var3 = tf.nn.moments(L3_BN,[0])\n",
    "scale3 = tf.Variable(tf.ones([512]))\n",
    "beta3 = tf.Variable(tf.zeros([512]))\n",
    "BN3 = tf.nn.batch_normalization(L3_BN, batch_mean3, batch_var3, beta3, scale3, epsilon)\n",
    "L3_BN = tf.nn.relu(BN3)\n",
    "L3_BN = tf.nn.dropout(L3_BN, keep_prob)\n",
    "\n",
    "'''\n",
    "W4 = tf.Variable(tf.random_normal([512, 256], stddev=0.01))\n",
    "#W3 = tf.get_variable(\"W3\", shape=[512, 256], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "B4 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4)+B4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob)\n",
    "'''\n",
    "\n",
    "#W4_BN = tf.Variable(tf.random_normal([512, 256], stddev=0.01))\n",
    "W4_BN = tf.get_variable(\"W4_BN\", shape=[512, 256], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L4_BN = tf.matmul(L3_BN, W4_BN)\n",
    "batch_mean4, batch_var4 = tf.nn.moments(L4_BN,[0])\n",
    "scale4 = tf.Variable(tf.ones([256]))\n",
    "beta4 = tf.Variable(tf.zeros([256]))\n",
    "BN4 = tf.nn.batch_normalization(L4_BN, batch_mean4, batch_var4, beta4, scale4, epsilon)\n",
    "L4_BN = tf.nn.relu(BN4)\n",
    "L4_BN = tf.nn.dropout(L4_BN, keep_prob)\n",
    "\n",
    "'''\n",
    "W5 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "#W4 = tf.get_variable(\"W4\", shape=[256, 10], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "B5 = tf.Variable(tf.random_normal(shape=[10], stddev=0.01))\n",
    "model = tf.nn.softmax(tf.matmul(L4,W5)+B5)\n",
    "'''\n",
    "\n",
    "#W5_BN = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "W5_BN = tf.get_variable(\"W5_BN\", shape=[256, 10], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L5_BN = tf.matmul(L4_BN, W5_BN)\n",
    "batch_mean5, batch_var5 = tf.nn.moments(L5_BN,[0])\n",
    "scale5 = tf.Variable(tf.ones([10]))\n",
    "beta5 = tf.Variable(tf.zeros([10]))\n",
    "BN5 = tf.nn.batch_normalization(L5_BN, batch_mean5, batch_var5, beta5, scale5, epsilon)\n",
    "model = tf.nn.softmax(BN5)\n",
    "\n",
    "#cost function and optimizer\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(tf.clip_by_value(model, 1e-10,1.0)), [1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(init)\n",
    "\n",
    "#set up for minibatch\n",
    "batch_size=100\n",
    "total_batch= int(mnist.train.num_examples/batch_size) \n",
    "\n",
    "#set up for accuracy\n",
    "is_correct = tf.equal(tf.argmax(model,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "#training\n",
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        #_, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        #total_cost += cost_val\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.5})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "        #print('Epoch:', '%04d' % (epoch + 1), 'Avg. cost =', '{:.3f}'.format(total_cost / total_batch), \n",
    "              #'Train Acc. =', sess.run(accuracy, feed_dict={X: mnist.train.images, Y: mnist.train.labels}))\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'Avg. cost =', '{:.3f}'.format(total_cost / total_batch), 'Train Acc. =', sess.run(accuracy, feed_dict={X: mnist.train.images, Y: mnist.train.labels, keep_prob: 1.0}))\n",
    "\n",
    "#print(\"Training Done\")\n",
    "#print(\"Test Acc.=\", sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "        \n",
    "print('Training Done!')\n",
    "print('Test Acc. = ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
