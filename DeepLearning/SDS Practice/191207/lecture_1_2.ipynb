{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "## Iris dataset\n",
    "\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis. It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. Two of the three species were collected in the Gaspé Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus\".\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other.\n",
    "\n",
    "![iris](800px-Iris_sanguinea.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sds\\miniconda3\\envs\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\sds\\miniconda3\\envs\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\sds\\miniconda3\\envs\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\sds\\miniconda3\\envs\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\sds\\miniconda3\\envs\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\sds\\miniconda3\\envs\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0            6.4         2.8          5.6         2.2        2\n",
       "1            5.0         2.3          3.3         1.0        1\n",
       "2            4.9         2.5          4.5         1.7        2\n",
       "3            4.9         3.1          1.5         0.1        0\n",
       "4            5.7         3.8          1.7         0.3        0\n",
       "..           ...         ...          ...         ...      ...\n",
       "115          5.5         2.6          4.4         1.2        1\n",
       "116          5.7         3.0          4.2         1.2        1\n",
       "117          4.4         2.9          1.4         0.2        0\n",
       "118          4.8         3.0          1.4         0.1        0\n",
       "119          5.5         2.4          3.7         1.0        1\n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract features and labels from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "label = 'Species'\n",
    "train_x = train[features].values\n",
    "train_y = train[label].values\n",
    "test_x = test[features].values\n",
    "test_y = test[label].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to construct a linear model that classifies label(species) using features(sepal_length, sepal_width, petal_length, petal_width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.352169   5.9073877 -7.74756  ]\n",
      " [ 2.7124155  4.724131  -3.3937638]\n",
      " [ 2.52631    4.28105   -5.6028543]\n",
      " [ 2.794335   4.60717    1.6587235]\n",
      " [ 3.302449   5.406629   2.0552087]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([4, 3]))\n",
    "b = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "logits = tf.matmul(x, W) + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print( sess.run(logits, {x:train_x})[:5] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax\n",
    "This function performs the equivalent of\n",
    "\n",
    "softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "\n",
    "We apply softmax to logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0 100]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0 100]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0 100]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0 100]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0 100]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0 100]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]\n",
      " [  0   0  99]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([4, 3]))\n",
    "b = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "logits = tf.matmul(x, W) + b\n",
    "prob = tf.nn.softmax(logits)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print( (sess.run(prob, {x:train_x})*100).astype(np.int32) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding, cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_encoded = pd.get_dummies(train_y).values\n",
    "print(train_y[:5])\n",
    "train_y_encoded[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-30-90aa4bd533fc>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "0 530.09937\n",
      "100 10.189713\n",
      "200 9.814674\n",
      "300 8.841625\n",
      "400 8.723039\n",
      "500 8.624154\n",
      "600 8.466415\n",
      "700 8.271529\n",
      "800 8.063454\n",
      "900 7.857594\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([4, 3]))\n",
    "b = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "logits = tf.matmul(x, W) + b\n",
    "loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(.005)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1000):\n",
    "        l, W_np, b_np, _ = sess.run((loss, W, b, train_op), {x:train_x, y:train_y_encoded})\n",
    "        if step % 100 == 0:\n",
    "            print(step, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species  prediction\n",
       "0          6.4         2.8          5.6         2.2        2           2\n",
       "1          5.0         2.3          3.3         1.0        1           1\n",
       "2          4.9         2.5          4.5         1.7        2           2\n",
       "3          4.9         3.1          1.5         0.1        0           0\n",
       "4          5.7         3.8          1.7         0.3        0           0\n",
       "5          4.4         3.2          1.3         0.2        0           0\n",
       "6          5.4         3.4          1.5         0.4        0           0\n",
       "7          6.9         3.1          5.1         2.3        2           2\n",
       "8          6.7         3.1          4.4         1.4        1           1\n",
       "9          5.1         3.7          1.5         0.4        0           0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(features, labels, W, b):\n",
    "    n = features.shape[0]\n",
    "    y = np.argmax(np.matmul(features,W)+b, axis=1)\n",
    "    \n",
    "    return sum(y == labels)/n\n",
    "\n",
    "train_logit = np.matmul(train_x,W_np)+b_np\n",
    "train_copy = train.copy()\n",
    "train_copy['prediction'] = np.argmax(train_logit,axis=1)\n",
    "print(accuracy(train_x,train_y,W_np,b_np))\n",
    "train_copy[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(test_x,test_y,W_np,b_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist dataset\n",
    "\n",
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y),_ = tf.keras.datasets.mnist.load_data()\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(train_x)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 31941, label : 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAM+ElEQVR4nO3dYawV9ZnH8d9PLTFaUFwDIUK0Eo272bh2xRsjZMPGtLq+wcZ0U15sWJbk1qQkbbIvNN0XJdms0c22+7LxErS4QWuNGEljtlVSqxsT4tW4CkWqa7BQrpArYuEFFOHZF3fYvcI9M5czM2eOPN9PcnPOmefMzNNTf8yc859z/o4IAbjwXdR1AwAGg7ADSRB2IAnCDiRB2IEkLhnkzmzz0T/QsojwTMtrHdlt3217j+33bT9YZ1sA2uV+x9ltXyzpt5K+Jmm/pNclrY6I35Ssw5EdaFkbR/YRSe9HxAcR8UdJP5W0qsb2ALSoTtivkbRv2uP9xbLPsT1qe9z2eI19Aaipzgd0M50qnHOaHhFjksYkTuOBLtU5su+XtGTa48WSDtRrB0Bb6oT9dUk32P6K7TmSviVpWzNtAWha36fxEfGZ7fWSfiHpYkmPRcSuxjoD0Ki+h9762hnv2YHWtXJRDYAvDsIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkhjolM344lm2bFlp/ZlnnimtHzt2rGftjjvuKF336NGjpXWcH47sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+woddddd5XWr7322tL66dOne9bmzZtXui7j7M2qFXbbeyUdlXRK0mcRUX4FBoDONHFk/+uImGxgOwBaxHt2IIm6YQ9Jv7T9hu3RmZ5ge9T2uO3xmvsCUEPd0/jlEXHA9gJJL9p+NyJemf6EiBiTNCZJtqPm/gD0qdaRPSIOFLeHJD0naaSJpgA0r++w277c9twz9yV9XdLOphoD0Kw6p/ELJT1n+8x2noyI/2ykKwzMkiVLSuvr16+vtf0TJ070rJ08ebLWtnF++g57RHwg6S8a7AVAixh6A5Ig7EAShB1IgrADSRB2IAm+4nqBu+ii8n/PN2zYUFpfuHBhrf1fdtllPWtz5syptW2cH47sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+wXuKqfgl67dm2r+//oo4961j799NNW943P48gOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzn4BKJs2+cknnxxgJ+c6fPhwzxpTMg8WR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9i+ASy4p/7/p6aef7lm74oorStednJwsrV955ZWl9areXnrppdI6BqfyyG77MduHbO+ctuwq2y/afq+4nd9umwDqms1p/E8k3X3WsgclbY+IGyRtLx4DGGKVYY+IVySdfc3jKkmbi/ubJd3bcF8AGtbve/aFETEhSRExYXtBryfaHpU02ud+ADSk9Q/oImJM0pgk2Y629wdgZv0OvR20vUiSittDzbUEoA39hn2bpDXF/TWSnm+mHQBtqTyNt/2UpJWSrra9X9IPJD0s6We210n6naRvttlkdo888khpfWRkpGft1KlTpetu2rSptP7AAw+U1qu88MILtdZHcyrDHhGre5TubLgXAC3iclkgCcIOJEHYgSQIO5AEYQeS4CuuQ+DOO8sHNtatW9f3tu+///7S+q5du0rrdYfeMDw4sgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzD0DVzzE/9NBDpfV58+aV1nfs2NGz9sQTT5Sue+utt5bWceHgyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOPgC33XZbab3sp6AlKaJ8Ip21a9f2rJ08ebJ03bbZ7nT/+H8c2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZB2D58uWl9apx9CobN27sWXv55ZdL1z1+/HitfVep+7+tzJw5c0rrixcv7lk7ceJE6bpz584trb/77rul9WFUeWS3/ZjtQ7Z3Tlu2wfbvbb9V/N3TbpsA6prNafxPJN09w/J/j4hbir8Xmm0LQNMqwx4Rr0g6PIBeALSozgd0622/XZzmz+/1JNujtsdtj9fYF4Ca+g37jyUtlXSLpAlJP+z1xIgYi4hlEbGsz30BaEBfYY+IgxFxKiJOS9ooqfxrWwA611fYbS+a9vAbknb2ei6A4eCqcVDbT0laKelqSQcl/aB4fIukkLRX0rcjYqJyZ3Z7g65DbMWKFaX1xx9/vLS+dOnSJtsZqLLx6CNHjtTa9oIFC0rr119/fd/brhqHv/HGG0vr+/bt63vfdUXEjD8iUHlRTUSsnmHxptodARgoLpcFkiDsQBKEHUiCsANJEHYgicqht0Z3lnTorUqdr2pK0n333dezVjVEdNNNN5XWq76ee6GamCgfSb755ptL6x9//HGT7ZyXXkNvHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ZO7/fbbS+uvvfZare2PjY31rO3Zs6fWticnJ/uuf/jhh6XrVo2zf/LJJ6X1LjHODiRH2IEkCDuQBGEHkiDsQBKEHUiCsANJMGVzclVTE9f16quv9qxt2bKl1X3j8ziyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLMn1/bvwld95xyDU3lkt73E9q9s77a9y/Z3i+VX2X7R9nvF7fz22wXQr9mcxn8m6R8j4k8l3S7pO7b/TNKDkrZHxA2SthePAQypyrBHxEREvFncPyppt6RrJK2StLl42mZJ97bVJID6zus9u+3rJH1V0g5JCyNiQpr6B8H2gh7rjEoardcmgLpmHXbbX5b0rKTvRcQf7Bl/0+4cETEmaazYBj84CXRkVkNvtr+kqaBviYitxeKDthcV9UWSDrXTIoAmVB7ZPXUI3yRpd0T8aFppm6Q1kh4ubp9vpUO0amRkpNXt79ixo9XtY/Zmcxq/XNLfSXrH9lvFsu9rKuQ/s71O0u8kfbOdFgE0oTLsEfFfknq9Qb+z2XYAtIXLZYEkCDuQBGEHkiDsQBKEHUiCr7gmd+mll9Za//jx46X1I0eO1No+msORHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJw9ua1bt5bWV65cWVp/9NFHG+wGbeLIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJOGJwk7QwIwzQvoiY8degObIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKVYbe9xPavbO+2vcv2d4vlG2z/3vZbxd897bcLoF+VF9XYXiRpUUS8aXuupDck3SvpbyUdi4h/m/XOuKgGaF2vi2pmMz/7hKSJ4v5R27slXdNsewDadl7v2W1fJ+mrknYUi9bbftv2Y7bn91hn1Pa47fFanQKoZdbXxtv+sqRfS/qXiNhqe6GkSUkh6Z81dar/DxXb4DQeaFmv0/hZhd32lyT9XNIvIuJHM9Svk/TziPjziu0QdqBlfX8RxrYlbZK0e3rQiw/uzviGpJ11mwTQntl8Gr9C0quS3pF0ulj8fUmrJd2iqdP4vZK+XXyYV7YtjuxAy2qdxjeFsAPt4/vsQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJCp/cLJhk5I+nPb46mLZMBrW3oa1L4ne+tVkb9f2Kgz0++zn7Nwej4hlnTVQYlh7G9a+JHrr16B64zQeSIKwA0l0HfaxjvdfZlh7G9a+JHrr10B66/Q9O4DB6frIDmBACDuQRCdht3237T2237f9YBc99GJ7r+13immoO52frphD75DtndOWXWX7RdvvFbczzrHXUW9DMY13yTTjnb52XU9/PvD37LYvlvRbSV+TtF/S65JWR8RvBtpID7b3SloWEZ1fgGH7ryQdk/TEmam1bP+rpMMR8XDxD+X8iHhgSHrboPOcxrul3npNM/736vC1a3L68350cWQfkfR+RHwQEX+U9FNJqzroY+hFxCuSDp+1eJWkzcX9zZr6j2XgevQ2FCJiIiLeLO4flXRmmvFOX7uSvgaii7BfI2nftMf7NVzzvYekX9p+w/Zo183MYOGZabaK2wUd93O2ymm8B+msacaH5rXrZ/rzuroI+0xT0wzT+N/yiPhLSX8j6TvF6Spm58eSlmpqDsAJST/ssplimvFnJX0vIv7QZS/TzdDXQF63LsK+X9KSaY8XSzrQQR8ziogDxe0hSc9p6m3HMDl4Zgbd4vZQx/38n4g4GBGnIuK0pI3q8LUrphl/VtKWiNhaLO78tZupr0G9bl2E/XVJN9j+iu05kr4laVsHfZzD9uXFByeyfbmkr2v4pqLeJmlNcX+NpOc77OVzhmUa717TjKvj167z6c8jYuB/ku7R1Cfy/yPpn7rooUdf10v67+JvV9e9SXpKU6d1JzV1RrRO0p9I2i7pveL2qiHq7T80NbX325oK1qKOeluhqbeGb0t6q/i7p+vXrqSvgbxuXC4LJMEVdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8ChCj7MK7f6CkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(train_x.shape[0])\n",
    "\n",
    "print('idx: {}, label : {}'.format(idx, train_y[idx]))\n",
    "plt.imshow(train_x[idx], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape\n",
    "If we flatten the two dimensional 28 by 28 array to an one dimensional 784(28 times 28) array. Then the problem is similar to the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 100, 195, 254, 237,\n",
       "       153,  19,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 189, 249, 253,\n",
       "       254, 253, 253, 236,  17,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17, 203, 253,\n",
       "       251, 196,  80,  96, 224, 253, 199,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9, 209,\n",
       "       254, 236, 113,   0,   0,   0,  49, 253, 254,  23,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       141, 254, 185,  42,   0,   0,   0,   0,   9, 210, 255, 115,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 207, 253,  93,   0,   0,   0,   0,   0,   0, 184, 254,\n",
       "       115,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  71,  46,  17,   0,   0,   0,   0,   0,  19,\n",
       "       240, 254,  73,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  24, 253, 254,  23,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  49, 254, 254,  23,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  26, 224, 253, 140,   2,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  28,\n",
       "       116, 174, 207, 199, 116,  91, 166, 253, 244,  17,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  26,\n",
       "       176, 240, 253, 254, 253, 253, 253, 254, 253, 253, 128,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 221, 254, 254, 203,  93,  93, 127, 185, 254, 254, 254, 220,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 134, 254, 194,  73,   6,   0,   0,  30, 180, 254, 210,\n",
       "       115,  81,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  19, 240, 247,  21,   0,   0,   0,  13, 161, 253,\n",
       "       205,  29,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  91, 253, 184,   0,   0,   0,  26, 180,\n",
       "       253, 185,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 116, 254,  93,   0,   0,  51,\n",
       "       221, 254, 214,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  99, 253, 189,  47,\n",
       "       130, 247, 254, 177,  29,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 253,\n",
       "       254, 253, 253, 253, 146,  21,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         7, 135, 254, 253, 244,  94,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.randint(train_x.shape[0])\n",
    "\n",
    "train_x_reshaped = train_x.reshape((60000,28*28))\n",
    "print(train_x_reshaped.shape)\n",
    "train_x_reshaped[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous example, we encode labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_encoded = pd.get_dummies(train_y).values\n",
    "train_y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Training\n",
    "\n",
    "Not enough memory for the whole dataset!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, features, labels):\n",
    "    idx = np.arange(0 , features.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [features[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function to generate random samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x, batch_y = next_batch(64,train_x_reshaped,train_y_encoded)\n",
    "print(batch_x.shape)\n",
    "batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this sample to update weights stochastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 135262.17\n",
      "100 192247.67\n",
      "200 501113.12\n",
      "300 334951.56\n",
      "400 260822.25\n",
      "500 535673.0\n",
      "600 324359.8\n",
      "700 383789.78\n",
      "800 819399.9\n",
      "900 277736.06\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "num_features = 28*28\n",
    "num_labels = 10\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([num_features, num_labels]))\n",
    "b = tf.Variable(tf.truncated_normal([num_labels]))\n",
    "\n",
    "logits = tf.matmul(x, W) + b\n",
    "loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(.005)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1000):\n",
    "        batch_x, batch_y = next_batch(64,train_x_reshaped,train_y_encoded)\n",
    "        l, W_np, b_np, _ = sess.run((loss, W, b, train_op), {x:batch_x, y:batch_y})\n",
    "        if step % 100 == 0:\n",
    "            print(step, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  80975.55  -105468.625  306061.25   108940.93   -10756.735 -102989.484\n",
      "   54909.934 -183701.58   -39801.895 -103335.36 ]\n",
      "label: 2, prediction: 2, CORRECT\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(train_x.shape[0])\n",
    "\n",
    "plt.imshow(train_x[idx], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "label_np = train_y[idx]\n",
    "logits_np = np.matmul(train_x_reshaped[idx],W_np)+b_np\n",
    "prediction = np.argmax(logits_np)\n",
    "print( logits_np )\n",
    "print( 'label: {}, prediction: {}, {}'.format(label_np,prediction, 'CORRECT' if label_np==prediction else 'INCORRECT') )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 58855.40234375\n",
      "epoch: 5, loss: 226311.5625\n",
      "epoch: 10, loss: 373320.875\n",
      "epoch: 15, loss: 329380.40625\n",
      "epoch: 19, loss: 576050.375\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "num_features = 28*28\n",
    "num_labels = 10\n",
    "batch_size = 64\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([num_features, num_labels]))\n",
    "b = tf.Variable(tf.truncated_normal([num_labels]))\n",
    "\n",
    "logits = tf.matmul(x, W) + b\n",
    "loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(.005)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(20):\n",
    "        num_batch = int(train_x.shape[0]//batch_size)\n",
    "        for _ in range(num_batch):\n",
    "            batch_x, batch_y = next_batch(64,train_x_reshaped,train_y_encoded)\n",
    "            l, W_np, b_np, _ = sess.run((loss, W, b, train_op), {x:batch_x, y:batch_y})\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print('epoch: {}, loss: {}'.format(epoch, l))\n",
    "    \n",
    "    print('epoch: {}, loss: {}'.format(epoch, l))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
