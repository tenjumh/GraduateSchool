{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "colab_type": "code",
    "id": "T7-6F52BrsF4",
    "outputId": "900cec5a-20f7-40f5-fa1f-55e5bed3d618"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-ae6f13b82cd9>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# session 생성시 tf.Session()대신 tf.Session(config=config)로 대체 바랍니다!\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "'''\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "'''\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#setup place holder for data and label\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "colab_type": "code",
    "id": "b88qyFQ2rtn2",
    "outputId": "e84abf7c-6f0a-42e7-f91b-ce32ab903002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-e1198c4d9162>:12: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch: 0001 Avg. cost = 0.912 Train Acc. = 0.9600545\n",
      "Epoch: 0002 Avg. cost = 0.335 Train Acc. = 0.9702727\n",
      "Epoch: 0003 Avg. cost = 0.247 Train Acc. = 0.9774909\n",
      "Epoch: 0004 Avg. cost = 0.208 Train Acc. = 0.9812545\n",
      "Epoch: 0005 Avg. cost = 0.181 Train Acc. = 0.98481816\n",
      "Epoch: 0006 Avg. cost = 0.157 Train Acc. = 0.9863273\n",
      "Epoch: 0007 Avg. cost = 0.144 Train Acc. = 0.98825455\n",
      "Epoch: 0008 Avg. cost = 0.130 Train Acc. = 0.9891273\n",
      "Epoch: 0009 Avg. cost = 0.117 Train Acc. = 0.9909091\n",
      "Epoch: 0010 Avg. cost = 0.111 Train Acc. = 0.99169093\n",
      "Epoch: 0011 Avg. cost = 0.103 Train Acc. = 0.9919636\n",
      "Epoch: 0012 Avg. cost = 0.093 Train Acc. = 0.9932182\n",
      "Epoch: 0013 Avg. cost = 0.091 Train Acc. = 0.9942182\n",
      "Epoch: 0014 Avg. cost = 0.084 Train Acc. = 0.9932\n",
      "Epoch: 0015 Avg. cost = 0.077 Train Acc. = 0.9949818\n",
      "Epoch: 0016 Avg. cost = 0.074 Train Acc. = 0.99514544\n",
      "Epoch: 0017 Avg. cost = 0.070 Train Acc. = 0.99570906\n",
      "Epoch: 0018 Avg. cost = 0.064 Train Acc. = 0.9964182\n",
      "Epoch: 0019 Avg. cost = 0.060 Train Acc. = 0.9967273\n",
      "Epoch: 0020 Avg. cost = 0.060 Train Acc. = 0.9965818\n",
      "Epoch: 0021 Avg. cost = 0.058 Train Acc. = 0.9973818\n",
      "Epoch: 0022 Avg. cost = 0.055 Train Acc. = 0.99756366\n",
      "Epoch: 0023 Avg. cost = 0.052 Train Acc. = 0.9977273\n",
      "Epoch: 0024 Avg. cost = 0.048 Train Acc. = 0.9976364\n",
      "Epoch: 0025 Avg. cost = 0.050 Train Acc. = 0.9977091\n",
      "Epoch: 0027 Avg. cost = 0.042 Train Acc. = 0.9984\n",
      "Epoch: 0028 Avg. cost = 0.040 Train Acc. = 0.9985091\n",
      "Epoch: 0029 Avg. cost = 0.038 Train Acc. = 0.99874544\n",
      "Epoch: 0030 Avg. cost = 0.037 Train Acc. = 0.9987091\n",
      "Training Done!\n",
      "Test Acc. =  0.9869\n"
     ]
    }
   ],
   "source": [
    "# setup layers\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "epsilon = 1e-3\n",
    "\n",
    "#  Init_Weight : He\n",
    "W1_BN = tf.get_variable(\"W1_BN\", shape=[784, 2048], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L1_BN = tf.matmul(X, W1_BN)\n",
    "batch_mean1, batch_var1 = tf.nn.moments(L1_BN,[0])\n",
    "scale1 = tf.Variable(tf.ones([2048]))\n",
    "beta1 = tf.Variable(tf.zeros([2048]))\n",
    "BN1 = tf.nn.batch_normalization(L1_BN, batch_mean1, batch_var1, beta1, scale1, epsilon)\n",
    "L1_BN = tf.nn.relu(BN1)\n",
    "L1_BN = tf.nn.dropout(L1_BN, keep_prob)\n",
    "\n",
    "W2_BN = tf.get_variable(\"W2_BN\", shape=[2048, 2048], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L2_BN = tf.matmul(L1_BN, W2_BN)\n",
    "batch_mean2, batch_var2 = tf.nn.moments(L2_BN,[0])\n",
    "scale2 = tf.Variable(tf.ones([2048]))\n",
    "beta2 = tf.Variable(tf.zeros([2048]))\n",
    "BN2 = tf.nn.batch_normalization(L2_BN, batch_mean2, batch_var2, beta2, scale2, epsilon)\n",
    "L2_BN = tf.nn.relu(BN2)\n",
    "L2_BN = tf.nn.dropout(L2_BN, keep_prob)\n",
    "\n",
    "W3_BN = tf.get_variable(\"W3_BN\", shape=[2048, 1024], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L3_BN = tf.matmul(L2_BN, W3_BN)\n",
    "batch_mean3, batch_var3 = tf.nn.moments(L3_BN,[0])\n",
    "scale3 = tf.Variable(tf.ones([1024]))\n",
    "beta3 = tf.Variable(tf.zeros([1024]))\n",
    "BN3 = tf.nn.batch_normalization(L3_BN, batch_mean3, batch_var3, beta3, scale3, epsilon)\n",
    "L3_BN = tf.nn.relu(BN3)\n",
    "L3_BN = tf.nn.dropout(L3_BN, keep_prob)\n",
    "\n",
    "W4_BN = tf.get_variable(\"W4_BN\", shape=[1024, 1024], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L4_BN = tf.matmul(L3_BN, W4_BN)\n",
    "batch_mean4, batch_var4 = tf.nn.moments(L4_BN,[0])\n",
    "scale4 = tf.Variable(tf.ones([1024]))\n",
    "beta4 = tf.Variable(tf.zeros([1024]))\n",
    "BN4 = tf.nn.batch_normalization(L4_BN, batch_mean4, batch_var4, beta4, scale4, epsilon)\n",
    "L4_BN = tf.nn.relu(BN4)\n",
    "L4_BN = tf.nn.dropout(L4_BN, keep_prob)\n",
    "\n",
    "W5_BN = tf.get_variable(\"W5_BN\", shape=[1024, 512], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L5_BN = tf.matmul(L4_BN, W5_BN)\n",
    "batch_mean5, batch_var5 = tf.nn.moments(L5_BN,[0])\n",
    "scale5 = tf.Variable(tf.ones([512]))\n",
    "beta5 = tf.Variable(tf.zeros([512]))\n",
    "BN5 = tf.nn.batch_normalization(L5_BN, batch_mean5, batch_var5, beta5, scale5, epsilon)\n",
    "L5_BN = tf.nn.relu(BN5)\n",
    "L5_BN = tf.nn.dropout(L5_BN, keep_prob)\n",
    "\n",
    "W6_BN = tf.get_variable(\"W6_BN\", shape=[512, 512], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L6_BN = tf.matmul(L5_BN, W6_BN)\n",
    "batch_mean6, batch_var6 = tf.nn.moments(L6_BN,[0])\n",
    "scale6 = tf.Variable(tf.ones([512]))\n",
    "beta6 = tf.Variable(tf.zeros([512]))\n",
    "BN6 = tf.nn.batch_normalization(L6_BN, batch_mean6, batch_var6, beta6, scale6, epsilon)\n",
    "L6_BN = tf.nn.relu(BN6)\n",
    "L6_BN = tf.nn.dropout(L6_BN, keep_prob)\n",
    "\n",
    "W7_BN = tf.get_variable(\"W7_BN\", shape=[512, 256], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L7_BN = tf.matmul(L6_BN, W7_BN)\n",
    "batch_mean7, batch_var7 = tf.nn.moments(L7_BN,[0])\n",
    "scale7 = tf.Variable(tf.ones([256]))\n",
    "beta7 = tf.Variable(tf.zeros([256]))\n",
    "BN7 = tf.nn.batch_normalization(L7_BN, batch_mean7, batch_var7, beta7, scale7, epsilon)\n",
    "L7_BN = tf.nn.relu(BN7)\n",
    "L7_BN = tf.nn.dropout(L7_BN, keep_prob)\n",
    "\n",
    "W8_BN = tf.get_variable(\"W8_BN\", shape=[256, 10], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "L8_BN = tf.matmul(L7_BN, W8_BN)\n",
    "batch_mean8, batch_var8 = tf.nn.moments(L8_BN,[0])\n",
    "scale8 = tf.Variable(tf.ones([10]))\n",
    "beta8 = tf.Variable(tf.zeros([10]))\n",
    "BN8 = tf.nn.batch_normalization(L8_BN, batch_mean8, batch_var8, beta8, scale8, epsilon)\n",
    "model = tf.nn.softmax(BN8)\n",
    "\n",
    "#cost function and optimizer\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(tf.clip_by_value(model, 1e-10,1.0)), [1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#set up for minibatch\n",
    "batch_size=100\n",
    "total_batch= int(mnist.train.num_examples/batch_size) \n",
    "\n",
    "#set up for accuracy\n",
    "is_correct = tf.equal(tf.argmax(model,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "#training\n",
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.5})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'Avg. cost =', '{:.3f}'.format(total_cost / total_batch), 'Train Acc. =', sess.run(accuracy, feed_dict={X: mnist.train.images, Y: mnist.train.labels, keep_prob: 1.0}))\n",
    "\n",
    "#print(\"Training Done\")\n",
    "#print(\"Test Acc.=\", sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "        \n",
    "print('Training Done!')\n",
    "print('Test Acc. = ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4--H6QLrx2V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "9Layers_Dropout_BatchNormal_30Epoch_InitWeight_He_191130.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
