{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum\n",
    "\n",
    "- ì¼ë°˜ì ì¸ Gradient Descent Methods : ğ’˜^ğ‘¡=ğ’˜^(ğ‘¡âˆ’1)âˆ’ğœ‚ğ’ˆ^ğ‘¡<br>  *ğ’ˆ^ğ‘¡:  ì‹œê°„ tì—ì„œì˜ ê¸°ìš¸ê¸°<br>\n",
    "- Momentum Gradient Descent Methods :<br>\n",
    "  ğ’^ğ‘¡=ğ›¾ã€– ğ’ã€—^(ğ‘¡âˆ’1)+ğœ‚ğ’ˆ^ğ‘¡<br>\n",
    "  ğ’˜^ğ‘¡=ğ’˜^(ğ‘¡âˆ’1)âˆ’ğ’^ğ‘¡<br>\n",
    "  ê²°êµ­, ğ’^ğ‘¡=ğœ‚ğ’ˆ^ğ‘¡+ğ›¾ ğœ‚ğ’ˆ^(ğ‘¡âˆ’1)+ğ›¾^2 ğœ‚ğ’ˆ^(ğ‘¡âˆ’2)+â€¦<br>\n",
    "<br>\n",
    "- Momentumì´ë€ : Update parameters considering both the momentum and the gradient of the current position.\n",
    "![image.png](https://github.com/tenjumh/GraduateSchool/blob/master/DeepLearning/image/momentum%20update.png?raw=true)\n",
    "- Momentumì˜ ë‹¨ì ì€<br>\n",
    " 1) miss the position where to stop<br>\n",
    " 2) Simple addition of momentum may cause excessive update"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tasks 1]<br>\n",
    "í•™ìŠµë°ì´í„°ë¡œ (1.0,-0.5,1.0) í•˜ë‚˜ë§Œ ìˆë‹¤. Error functionì€ MSEì´ë‹¤. ì´ˆê¸°ì˜ ëª¨ë“  ì—°ê²° ê°€ì¤‘ì¹˜ëŠ” 1ì´ë‹¤. Activation functionì´ ReLUì´ê³ , Momentumì„ ì´ìš©í•˜ì—¬ í•™ìŠµí•œë‹¤. Momentum rateê³¼ learning rateì´ ê°ê° 1ì´ë‹¤. NNì˜ êµ¬ì¡°ëŠ” ì•„ë˜ì™€ ê°™ë‹¤. ì°¸ê³ ë¡œ í•™ìŠµë°ì´í„°ê°€ nê°œ ìˆì„ ë•Œ MSEì˜ ì •ì˜ëŠ” E=1/2âˆ‘(o_i-t_i )^2 ì´ë‹¤. t_i, o_iëŠ” ië²ˆì§¸ í•™ìŠµë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ NNê°€ ì¶œë ¥í•´ì•¼ í•  ëª©í‘œê°’ê³¼ NNì´ ì‹¤ì œë¡œ ì¶œë ¥í•œ ê°’ì„ ì˜ë¯¸í•œë‹¤.\n",
    "![image.png](https://github.com/tenjumh/GraduateSchool/blob/master/DeepLearning/image/momentum%20task.png?raw=true)\n",
    "1 epoch í›„ w1,w3 ê°’ì„ êµ¬í•˜ì‹œì˜¤. í’€ì´ë¥¼ ì œì‹œí•˜ì‹œì˜¤.<br>\n",
    "2 epoch í›„ w1,w3 ê°’ì„ êµ¬í•˜ì‹œì˜¤. í’€ì´ë¥¼ ì œì‹œí•˜ì‹œì˜¤.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[í’€ì´]<br>\n",
    "\n",
    "[1 epoch]<br>\n",
    "<b>(foward)</b><br>\n",
    "net1 = x1*w1 + x2*w2 + b = 1*1 + (-0.5)*1 = 0.5<br>\n",
    "h1 = ReLu(net1) = 0.5<br>\n",
    "net2 = h1*w3 = 0.5<br>\n",
    "O = ReLu(net2) = 0.5<br>\n",
    "<b>(backward)</b><br>\n",
    "dE/dW3 = dE/dO*dO/dnet2*dnet2/dw3 = -(T-O)*(1 or 0)*h1 = -0.25<br>\n",
    "dE/dw1 = dE/dO*dO/dnet2*dnet2/dh1*dh1/dnet1*dnet1/dw1 = -(T-O)*(1 or 0)*w3*(1 or 0)*x1 = -0.5<br>\n",
    "dE/dw2 = dE/dO*dO/dnet2*dnet2/dh1*dh1/dnet1*dnet1/dw2 = -(T-O)*(1 or 0)*w3*(1 or 0)*x2 = 0.25<br>\n",
    "<br>\n",
    "M3 = rM(=0) + Lr*dE/dw3 = -0.25<br>\n",
    "w3 = W3 - M3 = 1.25<br>\n",
    "M1 = rM(=0) + Lr*dE/dw1 = -0.5<br>\n",
    "W1 = W1 - M1 = 1.5<br>\n",
    "M2 = rM(=0) + Lr*dE/dw2 = 0.25<br>\n",
    "w2 = W2 - M2 = 0.75<br>\n",
    "<br>\n",
    "[2 epoch]<br>\n",
    "<b>(foward)</b><br>\n",
    "net1 = x1*w1 + x2*w2 + b = 1*1.5 + (-0.5)*0.75 = 1.125<br>\n",
    "h1 = ReLu(net1) = 1.125<br>\n",
    "net2 = h1*w3 = 1.125*1.25 = 1.406<br>\n",
    "O = ReLu(net2) = 1.406<br>\n",
    "<b>(backward)</b><br>\n",
    "dE/dW3 = dE/dO*dO/dnet2*dnet2/dw3 = -(T-O)*(1 or 0)*h1 = 0.457<br>\n",
    "dE/dw1 = dE/dO*dO/dnet2*dnet2/dh1*dh1/dnet1*dnet1/dw1 = -(T-O)*(1 or 0)*w3*(1 or 0)*x1 = 0.508<br>\n",
    "dE/dw2 = dE/dO*dO/dnet2*dnet2/dh1*dh1/dnet1*dnet1/dw2 = -(T-O)*(1 or 0)*w3*(1 or 0)*x2 = -0.254<br>\n",
    "<br>\n",
    "M3 = rM(=0) + Lr*dE/dw3 = 0.207<br>\n",
    "w3 = W3 - M3 = 1.043<br>\n",
    "M1 = rM(=0) + Lr*dE/dw1 = 0.008<br>\n",
    "W1 = W1 - M1 = 1.492<br>\n",
    "M2 = rM(=0) + Lr*dE/dw2 = -0.004<br>\n",
    "w2 = W2 - M2 = 0.754<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=1 Epoch====\n",
      "(1, 2)\n",
      "m3: [[-0.25]]\n",
      "w3: [1.25]\n",
      "m: [[-0.5   0.25]]\n",
      "w: [1.5  0.75]\n",
      "=2 Epoch====\n",
      "(1, 2)\n",
      "m3: [[0.20703125]]\n",
      "w3: [1.04296875]\n",
      "m: [[ 0.0078125  -0.00390625]]\n",
      "w: [1.4921875  0.75390625]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lr = 1 #Learning rate\n",
    "iteration = 2\n",
    "Mr = 1 #momentum rate\n",
    "\n",
    "def ReLu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def ReLu_back(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "X = np.array([[1.0, -0.5]])\n",
    "T = np.array([[1.0]])\n",
    "\n",
    "w = np.array([1, 1])\n",
    "w3 = np.array([1])\n",
    "b = 0\n",
    "m, m3 = 0, 0\n",
    "\n",
    "for i in range(iteration):\n",
    "    print(\"={} Epoch====\".format(i+1))\n",
    "    net1 = np.dot(X, w) + b\n",
    "    h1 = ReLu(net1)\n",
    "    #print(\"h1:\", h1)\n",
    "    net2 = np.dot(h1, w3) + b\n",
    "    h2 = ReLu(net2)\n",
    "    #print(\"h2:\", h2)\n",
    "    o = h2\n",
    "    \n",
    "    dE_dW3 = -(T - o) * ReLu_back(o) * h1\n",
    "    dE_dW = -(T - o) * ReLu_back(o) * w3 * ReLu_back(h1) * X\n",
    "    m3 = Mr * m3 + lr * dE_dW3\n",
    "    w3 = w3 - m3\n",
    "    w3 = w3[0]\n",
    "    m = Mr * m + lr * dE_dW\n",
    "    w = w - m\n",
    "    w = w[0]\n",
    "    print('m3:', m3)\n",
    "    print('w3:', w3)\n",
    "    print('m:', m)\n",
    "    print('w:', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
